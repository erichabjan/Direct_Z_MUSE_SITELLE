{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table, join, QTable, vstack\n",
    "import astropy.units as u\n",
    "import sys\n",
    "import pyneb as pn\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "import math\n",
    "from astropy.io import fits\n",
    "from orcs.process import SpectralCube\n",
    "\n",
    "from astropy.nddata import NDData, Cutout2D\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "from reproject import reproject_interp\n",
    "from regions import PixCoord\n",
    "\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxynum = 5\n",
    "galdic = {1:'NGC4254', 2:'NGC4535', 3:'NGC3351', 4:'NGC2835', 5:'NGC0628'}  #There is no SITELLE data for NGC 4254, NGC 2835 has the best data \n",
    "galaxy = galdic[galaxynum]\n",
    "print(galaxy)\n",
    "\n",
    "### Import SITELLE data cube\n",
    "infile = f\"/home/habjan/jupfiles/data/{galaxy}_cube.hdf5\"\n",
    "cube = SpectralCube(infile);\n",
    "\n",
    "### Import MUSE image for reprojection\n",
    "hdul = fits.open(f\"/home/habjan/jupfiles/data/{galaxy}_IMAGE_FOV_Johnson_B_WCS_Pall_mad.fits\")\n",
    "muse_data = NDData(data=hdul['DATA'].data, mask=np.isnan(hdul['DATA'].data), meta=hdul['DATA'].header, wcs=WCS(hdul['DATA'].header))    \n",
    "muse_data.data[muse_data.data==0] = np.nan\n",
    "\n",
    "### Import Halpha Flux masks\n",
    "hdul = fits.open(f\"/home/habjan/jupfiles/data/{galaxy}_MAPS.fits\")\n",
    "Halpha = NDData(data=hdul['HA6562_FLUX'].data, mask=np.isnan(hdul['HA6562_FLUX'].data), meta=hdul['HA6562_FLUX'].header, wcs=WCS(hdul['HA6562_FLUX'].header))\n",
    "Halpha.data[muse_data.data==0] = np.nan\n",
    "\n",
    "### Import HII region spatial masks for locations of each HII region\n",
    "hdul = fits.open(f\"/home/habjan/jupfiles/data/{galaxy}_nebulae_mask_V2.fits\")        #nebulae_mask_V2 , HIIreg_mask\n",
    "nebulae_mask = NDData(data = hdul[0].data.astype(float), mask=Halpha.mask, meta=hdul[0].header, wcs=WCS(hdul[0].header)) \n",
    "nebulae_mask.data[nebulae_mask.data==-1] = np.nan\n",
    "\n",
    "### Import FITS cube to use WCS information\n",
    "hdul = fits.open(f\"/home/habjan/jupfiles/data/{galaxy}_cube.fits\")\n",
    "header = hdul[0].header\n",
    "wcs = WCS(header,naxis=2)\n",
    "\n",
    "### Import SITELLE deepframe image to reprject HII region mask\n",
    "hdul = fits.open(f\"/home/habjan/jupfiles/data/{galaxy}_deepframe.fits\")\n",
    "deepframe = NDData(data=hdul[0].data, meta=hdul[0].header, wcs=wcs)\n",
    "\n",
    "### Import PHANGS Nebular catalog\n",
    "infile = open(\"/home/habjan/jupfiles/data/Nebulae_catalogue_v3.fits\",'rb')     #Nebulae_catalogue_v3 , HIIregion_cat_DR2_native\n",
    "hdul = Table.read(infile)\n",
    "musedata = hdul[hdul['gal_name'] == f'{galaxy}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a list of HII region pixel locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = []\n",
    "pixamount = []\n",
    "\n",
    "for i in range(len(musedata)):\n",
    "    testcoord = WCS(nebulae_mask.meta).pixel_to_world(np.where(nebulae_mask.data == i)[1], np.where(nebulae_mask.data == i)[0])\n",
    "    if len(testcoord) == 0:\n",
    "        regions.append((np.array([]), np.array([])))\n",
    "        continue\n",
    "    sitpix = np.transpose(cube.world2pix((testcoord.ra.degree, testcoord.dec.degree)))\n",
    "    sitpix = sitpix[0].astype(np.int64), sitpix[1].astype(np.int64)\n",
    "    regions.append(sitpix)\n",
    "    pixamount.append(len(sitpix[0]))\n",
    "\n",
    "batches = 5\n",
    "batch = math.ceil(len(musedata)/batches)\n",
    "\n",
    "reglist = [regions[j:j+batch] for j in range(0, len(musedata), batch)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain wavelength array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavespec = cube.extract_integrated_spectrum(reglist[0][0])\n",
    "wave = np.array(np.real(wavespec[0]), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to extract a spectrum from the SITELLE cube for a given galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectra(sitcube, reg, inwave):\n",
    "\n",
    "    try:\n",
    "        spec = sitcube.extract_integrated_spectrum(reg)\n",
    "        flux = np.real(spec[1])/10**-20\n",
    "    \n",
    "    except: \n",
    "\n",
    "        flux = np.zeros(len(inwave))\n",
    "        flux[:] = np.nan\n",
    "\n",
    "    return flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    pronum = len(reglist)\n",
    "\n",
    "    paramlist = [[(cube, reglist[j][i], wave) for i in range(len(reglist[j]))] for j in range(len(reglist))]\n",
    "    \n",
    "    pool = mp.Pool(processes = pronum)          #count processes are inititiated\n",
    "\n",
    "    list1 = [pool.apply_async(spectra, args = p) for p in paramlist[0]]\n",
    "    list2 = [pool.apply_async(spectra, args = p) for p in paramlist[1]]\n",
    "    list3 = [pool.apply_async(spectra, args = p) for p in paramlist[2]]\n",
    "    list4 = [pool.apply_async(spectra, args = p) for p in paramlist[3]]\n",
    "    list5 = [pool.apply_async(spectra, args = p) for p in paramlist[4]]\n",
    "\n",
    "results1 = [list1[i].get() for i in range(len(list1))]\n",
    "results2 = [list2[i].get() for i in range(len(list2))]\n",
    "results3 = [list3[i].get() for i in range(len(list3))]\n",
    "results4 = [list4[i].get() for i in range(len(list4))]\n",
    "results5 = [list5[i].get() for i in range(len(list5))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile multiprocessing results into a single array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra1 = [np.array(results1[i], dtype=np.float64) for i in range(len(results1))]\n",
    "spectra2 = [np.array(results2[i], dtype=np.float64) for i in range(len(results2))]\n",
    "spectra3 = [np.array(results3[i], dtype=np.float64) for i in range(len(results3))]\n",
    "spectra4 = [np.array(results4[i], dtype=np.float64) for i in range(len(results4))]\n",
    "spectra5 = [np.array(results5[i], dtype=np.float64) for i in range(len(results5))]\n",
    "\n",
    "spectra = np.concatenate([spectra1, spectra2, spectra3, spectra4, spectra5], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sky Subtraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skyback(incube, nmask, phdata, ingal):\n",
    "\n",
    "    nebpix = (np.where(~np.isnan(nmask.data))[0], np.where(~np.isnan(nmask.data))[1])\n",
    "    testcoord = WCS(nmask.meta).pixel_to_world(nebpix[1], nebpix[0])\n",
    "    sitpix = np.transpose(incube.world2pix((testcoord.ra.degree, testcoord.dec.degree)))\n",
    "    sitpix = sitpix[0].astype(np.int64), sitpix[1].astype(np.int64)\n",
    "\n",
    "    r = np.max([np.max(sitpix[0]) - np.min(sitpix[0]), np.max(sitpix[1]) - np.min(sitpix[1])]) / 2 \n",
    "    rmin = r * 3\n",
    "    if ingal == 'NGC0628':\n",
    "        rmin = r * 2.5\n",
    "    rmax = np.sqrt(r**2 + rmin**2)\n",
    "\n",
    "    cenreg = np.where(np.min(phdata['deproj_dist']) == phdata['deproj_dist'])[0][0]\n",
    "    nebpix = (np.where(nmask.data == cenreg)[0], np.where(nmask.data == cenreg)[1])\n",
    "    testcoord = WCS(nmask.meta).pixel_to_world(nebpix[1], nebpix[0])\n",
    "    sitpix = np.transpose(incube.world2pix((testcoord.ra.degree, testcoord.dec.degree)))\n",
    "    sitpix = sitpix[0].astype(np.int64), sitpix[1].astype(np.int64)\n",
    "    x = np.median(sitpix[0])\n",
    "    y = np.median(sitpix[1])\n",
    "\n",
    "    imin = x - rmax\n",
    "    imax = x + rmax + 1\n",
    "    jmin = y - rmax\n",
    "    jmax = y + rmax + 1\n",
    "    xlist = []\n",
    "    ylist = []\n",
    "    buffval = 50\n",
    "\n",
    "    for i in np.arange(imin, imax):\n",
    "        if 0 + buffval <= i <= 2048 - buffval:\n",
    "            for j in np.arange(jmin, jmax):\n",
    "                if 0 + buffval <= j <= 2064 - buffval:\n",
    "                    ij = np.array([i,j])\n",
    "                    dist = np.linalg.norm(ij - np.array((x,y)))\n",
    "                    i, j = int(i), int(j)\n",
    "                    distnum = 3\n",
    "                    if dist > rmin and dist <= rmax:# and np.all(np.isnan(nmask.data[i-distnum:i+distnum,j-distnum:j+distnum])):\n",
    "                        xlist.append(i)\n",
    "                        ylist.append(j)\n",
    "\n",
    "    inpix = (xlist, ylist)\n",
    "\n",
    "    batchnum = 1000 \n",
    "    annuluslist = [(inpix[0][i:i+batchnum], inpix[1][i:i+batchnum]) for i in range(0, len(inpix[0]), batchnum)]\n",
    "    speclist = []\n",
    "\n",
    "    for i in range(len(annuluslist)):\n",
    "        try:\n",
    "            spec = incube.extract_integrated_spectrum(annuluslist[i], mean_flux=True)\n",
    "            speclist.append(np.real(spec[1]))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return np.mean(speclist, axis=0) / 10**-20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of Sky Background spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skyspec = skyback(cube, nebulae_mask, musedata, galaxy)\n",
    "skyspecs = np.array([skyspec * pixamount[i] for i in range(len(musedata))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an HDU object with the wavelengths, spectra and sky background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_hdu = fits.PrimaryHDU(wave)\n",
    "image_hdu = fits.ImageHDU(spectra)\n",
    "sky_hdu = fits.ImageHDU(skyspecs)\n",
    "\n",
    "spectab = fits.HDUList([primary_hdu, image_hdu, sky_hdu])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Spectra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectab.writeto(f'/home/habjan/jupfiles/data/{galaxy}_SITELLE_Spectra.fits', overwrite=True)  #, overwrite=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orb3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
